---
output:
      html_document: default
---

<style type="text/css">
  
  body{ /* Normal  */
      font-family: New Times Roman;
      font-size: 10px;
  }
td {  /* Table  */
    font-size: 10px;
}
h1 { /* Header 1 */
    font-size: 20px;
}
h2 { /* Header 2 */
    font-size: 22px;
}
h3 { /* Header 3 */
    font-size: 18px;
}
code.r{ /* Code block */
    font-size: 10px;
}
pre { /* Code block */
    font-size: 10px
}
</style>


```{r pacotes,cache = TRUE,echo=FALSE, warning = FALSE, error = FALSE}
# pacote utiliado para gráficos
library(ggplot2)
# pacote que deixa os gráficos do ggplot lado a lado
library(gridExtra)
# pacote para manipulação de dados
library(dplyr)
#pacote que possui o conjunto de dados para o primeiro exercício
library(car)
#pacote para fazer legenda
library(captioner)

figs <- captioner(prefix="Figura")
tbls <- captioner(prefix="Tabela")
#instalacao de um pacote pra "printar" tabelas mais bonitinhas
#install.packages(
#  'printr',
#  type = 'source',
#  repos = c('http://yihui.name/xran', 'http://cran.rstudio.com')
#)

```

```{r gráficos de resíduos,cache = TRUE,echo=FALSE}

# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo
# source("C:\\Users\\cnaber\\Trabalho\\windows\\Unicamp\\Disciplinas\\2_semestre_2016\\ME 613\\Programas\\diag2_norm.r")


diag2norm<-function(fit.model){
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"

par(mfrow=c(2,2))
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)
si <- lm.influence(fit.model)$sigma
tsi <- r/(si*sqrt(1-h))
a <- max(tsi)
b <- min(tsi)
par(mfrow=c(2,2))
#
plot(tsi,main = "A",xlab="Índice", ylab="Resíduo Studentizado",
ylim=c(b-1,a+1), pch=16,cex=1.1,cex.axis=1.1,cex.lab=1.1)
abline(2,0,lty=2)
abline(-2,0,lty=2)
abline(0,0,lty=2)
#identify(tsi, n=1)
#title(sub="(c)")
#
plot(fitted(fit.model),main = "B",tsi,xlab="Valores Ajustados", 
ylab="Resíduo Studentizado", ylim=c(b-1,a+1), pch=16,cex=1.1,cex.axis=1.1,cex.lab=1.1)
#
abline(2,0,lty=2)
abline(-2,0,lty=2)
abline(0,0,lty=2)
#boxplot(tsi,ylab="Resíduo Studentizado",cex=1.1,cex.axis=1.1,cex.lab=1.1)
hist(tsi,xlab="Resíduo Studentizado",ylab="densidade",probability=TRUE,main="C",cex=1.1,cex.axis=1.1,cex.lab=1.1)
#title(sub="(d)")
#identify(fitted(fit.model),tsi, n=1)
#
boxplot(tsi,main = "D",ylab="Resíduo Studentizado",cex=1.1,cex.axis=1.1,cex.lab=1.1)

#---------------------------------------------------------------#

}

# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo

envelnorm<-function(fit.model){
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"

#par(mfrow=c(1,1))
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
si <- lm.influence(fit.model)$sigma
r <- resid(fit.model)
tsi <- r/(si*sqrt(1-h))
#
ident <- diag(n)
epsilon <- matrix(0,n,100)
e <- matrix(0,n,100)
e1 <- numeric(n)
e2 <- numeric(n)
#
for(i in 1:100){
     epsilon[,i] <- rnorm(n,0,1)
     e[,i] <- (ident - H)%*%epsilon[,i]
     u <- diag(ident - H)
     e[,i] <- e[,i]/sqrt(u)
     e[,i] <- sort(e[,i]) }
#
for(i in 1:n){
     eo <- sort(e[i,])
     e1[i] <- (eo[2]+eo[3])/2
     e2[i] <- (eo[97]+eo[98])/2 }
#
med <- apply(e,1,mean)
faixa <- range(tsi,e1,e2)
#
#par(pty="s")
qqnorm(tsi,xlab="Percentil da N(0,1)",
ylab="Residuo Studentizado", ylim=faixa, pch=16, main="",cex=1.1,cex.axis=1.1,cex.lab=1.1)

par(new=T)
qqnorm(e1,axes=F,xlab="",ylab="",type="l",ylim=faixa,lty=1, main="")
par(new=T)
qqnorm(e2,axes=F,xlab="",ylab="", type="l",ylim=faixa,lty=1, main="")
par(new=T)
qqnorm(med,axes=F,xlab="",ylab="",type="l",ylim=faixa,lty=2, main="")
#------------------------------------------------------------#

}

```

```{r Teste Cbeta, cache=TRUE, echo=FALSE}
# fit.model: saída do modelo ajustado
# m.C: matriz C relativa às hipóteses de interesse

testeF.CB <- function(fit.model,m.C)
{
v.beta <-  cbind(fit.model$coef) # vetor com a estimativa dos parâmetros
n <- nrow(model.matrix(fit.model)) # número de observações
e.p <- nrow(v.beta) # número de parâmetros
e.q <- nrow(m.C)  # número de linhas da matriz C
m.cov.beta <- (vcov(fit.model)) # matriz de covariâncias dos parâmetros do modelo
# Estatística do Teste
e.F <- t(m.C%*%v.beta)%*%solve(m.C%*%m.cov.beta%*%t(m.C))%*%(m.C%*%v.beta)/e.q
e.pvalor <- 1-pf(e.F,e.q,n-e.p) # p-0valor
cat("Estatistica F = ",round(e.F,2),"\n")
cat("pvalor = ",round(e.pvalor,4),"\n")
cat("Matriz C :","\n")
print(m.C)
}

# fit.model: saída do modelo ajustado
# m.C: matriz C relativa às hipóteses de interesse
#m.M : matriz M relativa às hipóteses de interesse
testeF.CBM <- function(fit.model,m.C,m.M)

{
v.beta <-  cbind(fit.model$coef) # vetor com a estimativa dos parâmetros
n <- nrow(model.matrix(fit.model)) # número de observações
e.p <- nrow(v.beta) # número de parâmetros
e.q <- nrow(m.C)  # número de linhas da matriz C
m.cov.beta <- (vcov(fit.model)) # matriz de covariâncias dos parâmetros do modelo
# Estatística do teste
e.F <- t(m.C%*%v.beta-m.M)%*%solve(m.C%*%m.cov.beta%*%t(m.C))%*%(m.C%*%v.beta-m.M)/e.q
e.pvalor <- 1-pf(e.F,e.q,n-e.p) # p-valor
cat("Estatistica F = ",round(e.F,2),"\n")
cat("pvalor = ",round(e.pvalor,4),"\n")
cat("Matriz C :","\n")
print(m.C)
cat("Matriz M :","\n")
print(m.M)

}

```

```{r legendas, echo=FALSE, cache=TRUE}
# legenda para a primeira tabela(estats descr) do primeiro exercício
legenda1 = tbls(name="table_estat_descr1",caption = "Estatísticas Descritivas")
#legenda para o primeiro Boxplot


```


**Exercício 1**


```{r manipulacao_dados_exercicio_1, cache = TRUE ,echo = FALSE}
#retirada da observacao 12 e pegando só as variaveis sexo, peso e altura
dados_1 = Davis[-12,1:3]
names(dados_1)=c("Sexo","Peso","Altura")

Altf = subset(dados_1,Sexo=="F")
Altm = subset(dados_1,Sexo=="M")

Sexo = c(rep("F",nrow(Altf)),rep("M",nrow(Altm)))
Peso = c(Altf$Peso,Altm$Peso)
Altura = c(Altf$Altura,Altm$Altura)

Alturamf = (Altura-mean(Altura))
```

*Análise Descritiva*

*Estatísticas*
```{r,cache = TRUE,echo=FALSE}
library(printr)

medias = aggregate(.~Sexo,dados_1[,-1],mean)
dp = aggregate(.~Sexo,dados_1[,-1],sd)
maxs = aggregate(.~Sexo,dados_1[,-1],max)
mins = aggregate(.~Sexo,dados_1[,-1],min)

estat_descr = data.frame(medias,dp,maxs,mins)

estat_descr = estat_descr[c(-4,-7,-10)]
names(estat_descr)=c("Sexo","Média(Peso)","Média(Altura)","EP(Peso)","EP(Altura)","Máximo(Peso)","Máximo(Altura)","Mínimo(Peso)","Mínimo(Altura)")

estat_descr
```

`r legenda1`


*Gráficos*

```{r graf_box_1,cache = TRUE,echo=FALSE}
# boxplot sexo x peso
graf1 = ggplot(dados_1, aes(Sexo,Peso,fill=Sexo))
graf1 = graf1+geom_boxplot()+labs(title = "Boxplot: Sexo x Peso" , x = "Sexo", y="Peso")

# boxplot sexo x altura
graf2 = ggplot(dados_1, aes(Sexo,Altura,fill=Sexo))
graf2 = graf2 + geom_boxplot()+labs(title = "Boxplot: Sexo x Altura" , x = "Sexo", y="Altura")

grid.arrange(graf1, graf2, nrow=1, ncol=2)
```


### Dispersão entre Altura e Peso (Desconsiderando o sexo)

```{r disp_11, cache=TRUE,echo = FALSE}

graf3 = ggplot(dados_1, aes(Altura,Peso))
graf3+geom_point()+labs(title = "Dispersão entre as variáveis Altura e Peso" , x = "Altura", y="Peso")

```


### Dispersão entre Altura e Peso (Considerando o sexo)

```{r disp_12, cache=TRUE,echo = FALSE}
# Dispersão entre Altura e Peso (feminino)
graf4= ggplot(Altf, aes(Altura,Peso))
graf4=graf4+geom_point()+labs(title = "Dispersão considerando o sexo feminino" , x = "Altura", y="Peso")

# Dispersão entre Altura e Peso (masculino)
graf5 = ggplot(Altm, aes(Altura,Peso))
graf5 = graf5+geom_point()+labs(title = "Dispersão considerando o sexo masculino" , x = "Altura", y="Peso")
grid.arrange(graf4, graf5, nrow=1, ncol=2)
```


## Análise inferencial

Como modelo inicial, proporemos um modelo linear, considerando o intercepto


**Modelo 1**

$$Y_{ij} = \beta_0{i}+\beta_1{ij} (x_{ij}-\bar{x})+\varepsilon_{ij}$$

Com: $i = 1,2$ e $j=1,\dots, 199$

Significado dos parâmetros:

$B_0{ij}$: Valor esperado de $Y_{ij}$(Peso do individuo j do sexo i) para quando o valor de $x_{ij}$(Altura do individuo j do sexo i) é igual ao valor dá média amostral.

$B_1{ij}$: Incremento(positivo ou negativo) no peso quando se aumenta uma unidade de $x_{ij}$.

$\varepsilon_{ij}\sim \mathit{N}(0,\sigma ^{2})$

```{r,cache = TRUE,echo=FALSE}
fit_1 = lm(Peso~-1+Sexo+(Alturamf:Sexo))
resumo_fit_1 = summary(fit_1)
coeff_fit_1 = resumo_fit_1$coefficients
coeff_fit_1 = data.frame(round(as.double(coeff_fit_1[,1]),4),round(as.double(coeff_fit_1[,2]),4),round(as.double(coeff_fit_1[,3]),4),ifelse(as.double(coeff_fit_1[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_1[,4]),4)))

names(coeff_fit_1)=c("Estimado","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_modelo_11 = data.frame(rbind(AIC(fit_1),BIC(fit_1),logLik(fit_1)))
colnames(medidas_modelo_11)=c("Modelo 1")
rownames(medidas_modelo_11)=c("AIC","BIC","Log-Verossimilhança")

#matriz de planejamento
#View(data.frame(model.matrix(fit_1)))

#step
#step(fit_1,direction="both")
```

Todos os parâmetros são significativos, ou seja, todos contribuem para regressão, visto que seus p-valores são menores que 0,05.

Isso significa que há evidência de que eles são distintos de zero, 
importando que há valores esperado de peso para indivíduos que tem altura média e, existe 


### Análise de resíduos para o modelo

```{r,echo = FALSE}
diag2norm(fit_1)
```

Podemos notar que no gráfico A, não há indicios que possam levar a uma conclusão sobre dependência entre os dados

Já no gráfico B, pode-se notar 
que há uma possível leve heterocedasticidade nos dados pois entre os valores ajustados de 50 a 80, os Resíduos parecem se comportar de maneira que existem maiores discrepâncias nos valores dos resíduos, quanto mais perto de 80 for o valor ajustado, para valores ajustados maiores que 80, o comportamento torna-se menos distinto.

No gráfico C, nota-se uma leve assimetria positiva nos dados pois há mais concentração da densidade de probabilidade em valores de resíduos menores que zero, assim indicando uma leve assimetria e possível não normalidade doa dados.

No gráfico D, observa-se além da possível assimetria, a presença de outliers, podendo indicar que uma distribuição assimétrica com caudas meia pesadas que a distribuição Normal poderiamser consideradas à análise.

```{r,echo = FALSE}
envelnorm(fit_1)
```


**Modelo 2**

Considere o seguinte modelo quadrático, ainda com o fator Sexo:

$$Y_{ij} = \beta_0{i}+\beta_1{ij} (x_{ij}-\bar{x})+\beta_2{ij} (x_{ij}-\bar{x})^
{2}+\varepsilon_{ij}$$

Com: $i = 1,2$ e $j=1,\dots, 199$

Significado dos parâmetros:

$B_0{ij}$: Valor esperado de $Y_{ij}$(Peso do individuo j do sexo i) para quando o valor de $x_{ij}$(Altura do individuo j do sexo i) é igual ao valor dá média amostral.

$B_1{ij}$: Incremento(positivo ou negativo) no peso quando se aumenta uma unidade de $x_{ij}$.

$\varepsilon_{ij}\sim \mathit{N}(0,\sigma ^{2})$

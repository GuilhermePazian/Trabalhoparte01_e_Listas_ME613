---
title: ""
geometry: textwidth=18cm,textheight=21cm
setspace: doublespacing
lang: pt-br
header-includes:
- \usepackage{setspace} #pacote para espaço duplo
- \usepackage{indentfirst} #pacote para identação
- \usepackage[utf8]{inputenc}
- \usepackage{mathptmx}
- \usepackage{enumerate}
- \usepackage{url} #pacote para iserir link
- \usepackage{lipsum}
- \usepackage{multirow} #pacote para mesclar linhas de tabela
output:
  pdf_document:
  html_document: default
  fig_caption: yes
  mainfont: Times New Roman
  
fontsize: 10pt

---

\begin{titlepage}
\begin{center}
\thispagestyle{empty}
\begin{figure}[!htb]
\begin{center}
\begin{minipage}[b]{0.5\linewidth}
\begin{center}
\includegraphics[width=100pt,height=150pt]{logo/logoimeccunicamp.png}
\end{center}
\end{minipage}
\begin{minipage}[b]{0.7\linewidth}
\begin{center}
\vspace*{1cm}
 {\large \bf Universidade Estadual de Campinas\\[5pt]
Instituto de Matemática, Estatística e Computação Cientifica\\[3pt]
Departamento de Estatística}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\vspace*{\stretch{1}}
\begin{center}
\vspace*{5cm}
{\huge \bf Relatório - Parte I \\[7pt]
Trabalho Final de ME613}
\end{center}
\vspace*{\stretch{1}}
\begin{center}
\vspace*{4cm}
{\Large \bf Eliane Ramos de Siqueira  RA:155233 \\
Guilherme Pazian  RA:160323 \\
Henrique Capatto  RA:146406 \\
Murilo Salgado Razoli  RA:150987 \break
}\\[3pt]
{\large \bf Professor: Caio Lucidius Naberezny Azevedo}\\[5pt]
\end{center}
\vspace*{\stretch{1}}
\centerline{\bf Campinas-SP, 06 de Dezembro de 2016}
\vspace*{\stretch{1}}
\end{center}
\end{titlepage}

\onehalfspacing
\newpage

```{r pacotes,cache = TRUE,echo=FALSE, error = FALSE}
# pacote utiliado para gráficos
library(ggplot2)
# pacote que deixa os gráficos do ggplot lado a lado

# pacotes para manipulação de dados
library(reshape2)
library(plyr)
library(dplyr)
library(gridExtra)

#pacote que possui o conjunto de dados para o primeiro exercício
library(car)
#pacote para fazer legenda
library(captioner)
library(tidyverse)

figs <- captioner(prefix="Figura")
tbls <- captioner(prefix="Tabela")

#inslação dos pacotes necessários
#install.packages(C("tidyverse","gridExtra","car","captioner","gvlma"))

#instalacao de um pacote pra "printar" tabelas mais bonitinhas
#install.packages(
#  'printr',
#  type = 'source',
#  repos = c('http://yihui.name/xran', 'http://cran.rstudio.com')
#)

```

```{r gráficos de resíduos,cache = TRUE,echo=FALSE}

library(ggplot2)
library(gridExtra)
# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo
# source("C:\\Users\\cnaber\\Trabalho\\windows\\Unicamp\\Disciplinas\\2_semestre_2016\\ME 613\\Programas\\diag2_norm.r")

library(ggplot2)
diag2norm<-function(fit.model){
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)
si <- lm.influence(fit.model)$sigma
tsi <- r/(si*sqrt(1-h))
tam <- 1:length(tsi)
a <- max(tsi)
b <- min(tsi)

g1 = ggplot(data=data.frame(tam,tsi),aes(tam,tsi))+ geom_point() +scale_y_continuous(name = "Resíduo Studentizado",limits=c(b-1,a+1)) +scale_x_continuous(name = "Índice")+labs(title="A")+geom_hline(yintercept=0,size=0.25,linetype=2)+geom_hline(yintercept=2,size=0.25,linetype=2)+geom_hline(yintercept=-2,size=0.25,linetype=2)+theme_light()

g2 =  ggplot(data=data.frame(fitted(fit.model),tsi),aes(fitted(fit.model),tsi))+ geom_point() +scale_y_continuous(name = "Resíduo Studentizado",limits=c(b-1,a+1)) +scale_x_continuous(name = "Valores Ajustados")+labs(title="B")+geom_hline(yintercept=0,size=0.25,linetype=2)+geom_hline(yintercept=2,size=0.25,linetype=2)+geom_hline(yintercept=-2,size=0.25,linetype=2)+theme_light()

#Histograma
g3 = ggplot(data=data.frame(tsi),aes(tsi,col=I("black"),fill=I("white")))+geom_histogram(binwidth = 1,aes(y=..density..))+labs(title="C",x="Resíduo Studentizado",y="Densidade")+theme_light()

#Boxplot
g4 = ggplot(data=data.frame(fac = factor(1),tsi),aes(fac,tsi,col=I("black"),fill=I("white")))+ geom_boxplot(outlier.size = 1.5, outlier.colour = "red",width=0.4)+labs(title="D")+scale_x_discrete(name="")+scale_y_continuous(name = "Residuo Studentizado")+theme(axis.text.x = element_blank())+theme_light()

#funcao que une todos os gráficos
grid.arrange(g1,g2,g3,g4,ncol=2,nrow=2)
#---------------------------------------------------------------#

}

# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo e Henrique Capatto

envelnorm<-function(fit.model){  
# argumento: modelo de regressão linear homocedástico ajustado
# Eu adaptei uma função que achei na net com o que o Caio fez nos grafs de envelope. Agradeçam a um desconhecido.  

  
  
    X <- model.matrix(fit.model)
    n <- nrow(X)
    p <- ncol(X)
    H <- X%*%solve(t(X)%*%X)%*%t(X)
    h <- diag(H)
    si <- lm.influence(fit.model)$sigma
    r <- resid(fit.model)
    tsi <- r/(si*sqrt(1-h))
    #
    ident <- diag(n)
    epsilon <- matrix(0,n,100)
    e <- matrix(0,n,100)
    e1 <- numeric(n)
    e2 <- numeric(n)
    #
    for(i in 1:100){
        epsilon[,i] <- rnorm(n,0,1)
        e[,i] <- (ident - H)%*%epsilon[,i]
        u <- diag(ident - H)
        e[,i] <- e[,i]/sqrt(u)
        e[,i] <- sort(e[,i]) }
    #
    for(i in 1:n){
        eo <- sort(e[i,])
        e1[i] <- (eo[2]+eo[3])/2
        e2[i] <- (eo[97]+eo[98])/2 }
  
  
    y <- quantile(tsi[!is.na(tsi)], c(0.25, 0.75))
    x <- qnorm(c(0.25, 0.75))
    slope <- diff(y)/diff(x)
    int <- y[1L] - slope * x[1L]
  
    d <- data.frame(resids = tsi)
  
    ggplot(d, aes(sample = resids))+stat_qq()+stat_qq(aes(sample=e1),geom="line")+stat_qq(aes(sample=e2),geom="line")+ geom_abline(slope = slope, intercept = int,linetype = 3)+labs(x="Percentil da N(0,1)",y="Residuo Studentizado",title="E")+theme_light()
}


# Programa extraído do site: https://www.ime.usp.br/~giapaula/textoregressao.htm
# Créditos: Prof. Dr. Gilberto Alvarenga Paula
# Adaptado por Caio L. N. Azevedo
# source("C:\\Users\\cnaber\\Trabalho\\windows\\Unicamp\\Disciplinas\\2_semestre_2016\\ME 613\\Programas\\anainflu_norm.r")

anainflu_norm<-function(fit.model){
# fit.model: objeto com o ajuste do modelo normal linear homocedástico 
# obtido através da função "lm"
X <- model.matrix(fit.model)
n <- nrow(X)
p <- ncol(X)
H <- X%*%solve(t(X)%*%X)%*%t(X)
h <- diag(H)
lms <- summary(fit.model)
s <- lms$sigma
r <- resid(lms)
ts <- r/(s*sqrt(1-h))
di <- (1/p)*(h/(1-h))*(ts^2)
si <- lm.influence(fit.model)$sigma
tsi <- r/(si*sqrt(1-h))
a <- max(tsi)
b <- min(tsi)
par(mfrow=c(1,2))
plot(h,xlab="Índice", ylab="Medida h", pch=16, ylim=c(0,1),cex=1.1,cex.axis=1.1,cex.lab=1.1)
cut <- 2*p/n
abline(cut,0,lty=2)
#identify(h, n=1)
#title(sub="(a)")
#
plot(di,xlab="Índice", ylab="Distância de Cook", pch=16,cex=1.1,cex.axis=1.1,cex.lab=1.1)
#identify(di, n=2)
#
#------------------------------------------------------------#
}

```

```{r Teste Cbeta, cache=TRUE, echo=FALSE}
# fit.model: saída do modelo ajustado
# m.C: matriz C relativa às hipóteses de interesse

testeF.CB <- function(fit.model,m.C)
{
v.beta <-  cbind(fit.model$coef) # vetor com a estimativa dos parâmetros
n <- nrow(model.matrix(fit.model)) # número de observações
e.p <- nrow(v.beta) # número de parâmetros
e.q <- nrow(m.C)  # número de linhas da matriz C
m.cov.beta <- (vcov(fit.model)) # matriz de covariâncias dos parâmetros do modelo
# Estatística do Teste
e.F <- t(m.C%*%v.beta)%*%solve(m.C%*%m.cov.beta%*%t(m.C))%*%(m.C%*%v.beta)/e.q
e.pvalor <- 1-pf(e.F,e.q,n-e.p) # p-0valor
cat("Estatistica F = ",round(e.F,2),"\n")
cat("pvalor = ",round(e.pvalor,4),"\n")
cat("Matriz C :","\n")
print(m.C)
}

# fit.model: saída do modelo ajustado
# m.C: matriz C relativa às hipóteses de interesse
#m.M : matriz M relativa às hipóteses de interesse
testeF.CBM <- function(fit.model,m.C,m.M)

{
v.beta <-  cbind(fit.model$coef) # vetor com a estimativa dos parâmetros
n <- nrow(model.matrix(fit.model)) # número de observações
e.p <- nrow(v.beta) # número de parâmetros
e.q <- nrow(m.C)  # número de linhas da matriz C
m.cov.beta <- (vcov(fit.model)) # matriz de covariâncias dos parâmetros do modelo
# Estatística do teste
e.F <- t(m.C%*%v.beta-m.M)%*%solve(m.C%*%m.cov.beta%*%t(m.C))%*%(m.C%*%v.beta-m.M)/e.q
e.pvalor <- 1-pf(e.F,e.q,n-e.p) # p-valor
cat("Estatistica F = ",round(e.F,2),"\n")
cat("pvalor = ",round(e.pvalor,4),"\n")
cat("Matriz C :","\n")
print(m.C)
cat("Matriz M :","\n")
print(m.M)

}

```

```{r legendas, echo=FALSE, cache=TRUE}
#legenda para as tabelas

# legenda para a primeira tabela(estats descr) do primeiro exercício
legenda_table1 = tbls(name="table_estat_descr1",caption = "Estatísticas Descritivas")
legenda_table2 = tbls(name="table_aic_bic",caption = "Comparação dos modelos")
legenda_table3 = tbls(name="table_esti_testedenulidade",caption = "Estimativas dos parâmetros, intervalo de confiança e teste de nulidade")
#legendas para os gráficos

#legenda para o primeiro Boxplot
legenda_graf1 = figs(name="graf1_boxplot",caption = "Boxplot Comparativo")
#legenda para o primeiro grárico de dispersão
legenda_graf2 = figs(name="graf2_dispersao",caption = "Dispersão entre as variáveis Altura e Peso")
legenda_graf3 = figs(name="graf3_dispersao",caption = "Dispersão entre as variáveis Altura e Peso considerando o sexo.")
legenda_graf4 = figs(name="graf4_analiseresidual",caption = "Análise residual para o modelo 1")
legenda_graf5 = figs(name="graf5_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 1")
legenda_graf6 = figs(name="graf6_analiseresidual",caption = "Análise residual para o modelo 2")
legenda_graf7 = figs(name="graf7_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 2")
legenda_graf8 = figs(name="graf8_analiseresidual",caption = "Análise residual para o modelo 3")
legenda_graf9 = figs(name="graf9_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 3")
legenda_graf10 = figs(name="graf10_analiseresidual",caption = "Análise residual para o modelo 4")
legenda_graf11 = figs(name="graf11_envelope",caption = "Gráfico de envelope para o resíduos studentizado para o modelo 4")
legenda_graf12 = figs(name="graf12_Ajuste",caption = "Gráfico de pontos com a reta ajustada pelo modelo 1")


```

\begin{enumerate}
\item Introdução
\end{enumerate}
\vspace{0.3cm}
\setlength{\parindent}{3em}
  <p>O conjunto de dados analisado corresponde a informações de homens e mulheres envolvidos em exercícios regulares e apresenta para cada indivíduo, o peso(em kg) e altura(em cm) medidos e informados pelo mesmo. Além disso, o sexo de cada indivíduo também foi coletado, sendo que 112 são do sexo feminino e 88 são do sexo masculino, totalizando 200 pessoas.Os dados podem ser encontrados no R no pacote car, sob o nome "Davis".</p>\par
<p>O objetivo é estudar o impacto da altura no peso, levando em consideração o sexo.</p>
  <p>Utilizamos a metodologia dos modelos normais lineares homocedásticos, metodologias da qualidade do ajuste e comparação de modelos apropriados com o suporte computacional do R.</p>
</p>

\vspace{1.5cm}

```{r manipulacao_dados_exercicio_1, cache = TRUE ,echo = FALSE}
#retirada da observacao 12 e pegando só as variaveis sexo, peso e altura
dados_1 = Davis[-12,1:3]
names(dados_1)=c("Sexo","Peso","Altura")

df <- melt(dados_1,id.vars = 1)

Altf = subset(dados_1,Sexo=="F")
Altm = subset(dados_1,Sexo=="M")

Sexo = c(rep("F",nrow(Altf)),rep("M",nrow(Altm)))
Peso = c(Altf$Peso,Altm$Peso)
Altura = c(Altf$Altura,Altm$Altura)



Alturamf = c(Altf$Altura-mean(Altf$Altura),Altm$Altura-mean(Altm$Altura))

dadosalt = data.frame(Sexo,Peso,Alturamf)

```

\begin{enumerate}
\setcounter{enumi}{1}
\item Análise descritiva
\end{enumerate}
\vspace{0.3cm}

Observando a tabela 1, podemos ver que em média, o peso e a altura dos homens são maiores que os das mulheres. Além disso vemos valores superiores em todas as estatísticas, para os homens, incluindo uma maior variação nos dados, variação essa, mostrada pelos valores de erro padrão.  

\vspace{1cm}
\begin{center}
`r legenda_table1`
\end{center}


```{r,cache = TRUE,echo=FALSE}
#estatísticas
library(printr)

df <- melt(dados_1,id.vars = 1)
resumo <- ddply(df, c("Sexo","variable"), function(x) summary(x$value))
dp = ddply(df, c("Sexo","variable"), function(x) sd(x$value))
options(OutDec= ",")
estat_descr = data.frame(resumo,dp[,3])

names(estat_descr)=c("Sexo","Variável","Minímo","1ºQuartil","Mediana","Média","3ºQuartil","Máximo","Erro Padrão")

estat_descr
```

\vspace{0.5cm}
A figura 1 mostra um boxplot dos valores de peso por gênero e um boxplot dos valores de altura também por gênero. Observando-os podemos confirmar os padrões já identificados pelas estatísticas descritivas.

```{r graf_box_1,cache = TRUE,echo=FALSE, fig.height=3, fig.width=6,fig.align='center',warning=FALSE}
#gráficos
# boxplot sexo x peso
graf1 = ggplot(dados_1, aes(Sexo,Peso,fill=Sexo))
graf1 = graf1+geom_boxplot()+labs(title = "Boxplot: Sexo x Peso" , x = "Sexo", y="Peso")+theme_light()+ scale_fill_brewer(palette ="Blues")+theme(plot.title = element_text(hjust = 0.5))+theme(legend.position = "none")

# boxplot sexo x altura
graf2 = ggplot(dados_1, aes(Sexo,Altura,fill=Sexo))
graf2 = graf2 + geom_boxplot()+labs(title = "Boxplot: Sexo x Altura" , x = "Sexo", y="Altura")+theme_light()+ scale_fill_brewer(palette ="Blues")+theme(plot.title = element_text(hjust = 0.5))+theme(legend.position = "none")

grid.arrange(graf1, graf2, nrow=1, ncol=2)
```
\begin{center}
`r legenda_graf1`
\end{center}
\vspace{0.5cm}
Na figura 2 abaixo, temos um gráfico de dispersão do peso em relação a altura dos indivíduos, desconsiderando o gênero. Podemos perceber que há uma relação positiva entre a váriavel resposta(peso) e a variável explicativa(altura), isto é, quanto maior a altura, maior o peso do indivíduo. Tal relação pode ser razoavelmente representada por uma reta ou uma curva quadrática.

\vspace{0.6cm}
```{r disp_11, cache=TRUE,echo = FALSE,fig.align='center',fig.width=5.5,fig.height=3.4,warning=FALSE}
# Dispersão entre Altura e Peso (Desconsiderando o sexo)
ggplot(dados_1, aes(Altura,Peso))+geom_point()+labs(title = "Dispersão entre as variáveis Altura e Peso" , x = "Altura", y="Peso")+theme(plot.title = element_text(hjust = 0.5))+theme_light()
```
\begin{center}
`r legenda_graf2`
\end{center}

A figura 3 também apresenta os gráficos de dispersão entre a variável resposta e explicativa, desta vez considerando o sexo de cada indivíduo.
Podemos ver que para ambos os sexos,há uma relação positiva, o peso cresce a medida que a altura cresce. Além disso é possível notar a presença de um outlier para o sexo masculino, enquanto que para o sexo feminino podemos ver em torno de três outliers.
Tanto para o sexo feminino quanto o masculino podemos ainda razoavelmente representar esta relação entre peso e altura por uma reta ou uma curva quadrática.

\vspace{0.5cm}
```{r disp_12, cache=TRUE,echo = FALSE,fig.width=5.5,fig.height=3.5,fig.align='center'}
# Dispersão entre Altura e Peso (feminino)
graf4= ggplot(Altf, aes(Altura,Peso))
graf4=graf4+geom_point()+labs(title = "Sexo Feminino" , x = "Altura", y="Peso")+theme(plot.title = element_text(hjust = 0.5))+theme_light()

# Dispersão entre Altura e Peso (masculino)
graf5 = ggplot(Altm, aes(Altura,Peso))
graf5 = graf5+geom_point()+labs(title = "Sexo Masculino" , x = "Altura", y="Peso")+theme(plot.title = element_text(hjust = 0.5))+theme_light()
grid.arrange(graf4, graf5, nrow=1, ncol=2)
```
\begin{center}
`r legenda_graf3`
\end{center}

\vspace{0.5cm}
\begin{enumerate}
\setcounter{enumi}{2}
\item Análise Inferencial
\end{enumerate}
\vspace{0.3cm}
 
Devido ao objetivo em questão e aos resultados da análise descritiva, vamos considerar quatro modelos e verificar qual deles é o mais reduzido e melhor se ajusta aos dados.

Para os dois primeiros, consideramos modelos com intercepto, o primeiro deles, é um modelo linear centrado na média, enquanto que o segundo é um modelo quadrático também centrado na média. Esses dois modelos nos permite identificar se o intercepto modifica as análises sobre a significância da covariável sexo.

 Para os outros dois, consideramos o modelo sem intecepto, onde o primeiro deles é modelo linear e o segundo, um modelo quadrático. Tal sugestão foi feita, pois além dos objetivos descritos acima, desejamos identificar se esses modelos fornecem informação relevante, mesmo contendo menos paramêtros.

Dado a natureza dos dados, não faz sentido observarmos algum valor diferente de zero para a variavel resposta quando a variavel explicativa for é igual a zero, por isso, os modelos com intercepto sugeridos são todos centrados na média.

Modelo 1

$$Y_{ij} = \beta_{0i}+\beta_{1i} (x_{ij}-\bar{x_{i}})+\varepsilon_{ij} \left\{\begin{matrix}
i=1,2\\ 
j=1,\dots, 199\\ 
\end{matrix}\right.$$

Onde: $\varepsilon_{ij}\sim \mathit{N}(0,\sigma ^{2})$.
\vspace{0.3cm}
\begin{itemize}

\item $Y_{ij}$: Peso do j-ésimo indíviduo do i-ésimo sexo.
\item $x_{ij}$: Altura do j-ésimo indivíduo do i-ésimo sexo.
\item $\beta_{0i}$: Peso esperado para o indivíduo do i-ésimo sexo, quando sua altura é igual ao valor da média de cada grupo.

\item $\beta_{1i}$: Incremento (positivo ou negativo) no peso esperado do j-ésimo indivíduo do i-ésimo sexo, para o aumento em uma unidade na altura.

\end{itemize}

```{r,cache = TRUE,echo=FALSE}
#análise para o modelo 1
fit_1 = lm(Peso~-1+Sexo+(Alturamf:Sexo))
resumo_fit_1 = summary(fit_1)
coeff_fit_1 = resumo_fit_1$coefficients
coeff_fit_1 = data.frame(round(as.double(coeff_fit_1[,1]),4),round(as.double(coeff_fit_1[,2]),4),round(as.double(coeff_fit_1[,3]),4),ifelse(as.double(coeff_fit_1[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_1[,4]),4)))

names(coeff_fit_1)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_modelo_1 = data.frame(rbind(AIC(fit_1),BIC(fit_1),logLik(fit_1)))
colnames(medidas_modelo_1)=c("Modelo 1")
rownames(medidas_modelo_1)=c("AIC","BIC","Log-Verossimilhança")

#matriz de planejamento
#View(data.frame(model.matrix(fit_1)))

#step
#step(fit_1,direction="both")
#visualização da tabela
#library(xtable)
#print(xtable(coeff_fit_1))
```
\vspace{1cm}
Modelo 2

$$Y_{ij} = \beta_0{i}+\beta_1{i} (x_{ij}-\bar{x})+\beta_2{i} (x_{ij}-\bar{x})^
{2}+\varepsilon_{ij}\left\{\begin{matrix}
i=1,2\\ 
j=1,\dots, 199\\ 
\end{matrix}\right.$$

Onde: $\varepsilon_{ij}\sim \mathit{N}(0,\sigma ^{2})$
\vspace{0.3cm}
\begin{itemize}

\item $Y_{ij}$: Peso do j-ésimo indíviduo do i-ésimo sexo.
\item $x_{ij}$: Altura do j-ésimo indivíduo do i-ésimo sexo.
\item $\beta_{0i}$: Peso esperado indivíduo do i-ésimo sexo, quando sua altura é igual a média.
\item $\beta_{1i}$: Incremento(positivo ou negativo) no peso quando se aumenta em uma unidade o valor da altura.

\item $\frac{-\beta_{1i}}{2\beta_{2i}}$: Valor da altura para o qual o peso esperado é máximo ou mínimo.

\end{itemize}

```{r,cache = TRUE,echo=FALSE}
Alturamf2=Alturamf^2

fit_2 = lm(Peso~-1+Sexo+(Alturamf:Sexo)+(Alturamf2:Sexo))
resumo_fit_2 = summary(fit_2)
coeff_fit_2 = resumo_fit_2$coefficients
coeff_fit_2 = data.frame(round(as.double(coeff_fit_2[,1]),4),round(as.double(coeff_fit_2[,2]),4),round(as.double(coeff_fit_2[,3]),4),ifelse(as.double(coeff_fit_2[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_2[,4]),4)))

names(coeff_fit_2)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_modelo_2 = data.frame(rbind(AIC(fit_2),BIC(fit_2),logLik(fit_2)))
colnames(medidas_modelo_2)=c("Modelo 2")
rownames(medidas_modelo_2)=c("AIC","BIC","Log-Verossimilhança")

#matriz de planejamento
#View(data.frame(model.matrix(fit_1)))

#step
#step(fit_1,direction="both")
#library(xtable)
#print(xtable(coeff_fit_2))
```

\vspace{1cm}
Modelo 3

$$Y_{ij} = \beta_{1i} (x_{ij})+\varepsilon_{ij}\left\{\begin{matrix}
i=1,2\\ 
j=1,\dots, 199\\ 
\end{matrix}\right.$$

Com: $\varepsilon_{ij}\sim \mathit{N}(0,\sigma ^{2})$

\vspace{0.3cm}
\begin{itemize}

\item $Y_{ij}$: Peso do j-ésimo indíviduo do i-ésimo sexo.
\item $x_{ij}$: Altura do j-ésimo indivíduo do i-ésimo sexo.
\item $\beta_{1i}$: Incremento(positivo ou negativo) no peso quando se aumenta em uma unidade o valor da altura.


\end{itemize}
```{r,cache = TRUE,echo=FALSE}
#analise para o modelo 3
fit_3 = lm(Peso~-1+(Altura:Sexo),data=dados_1)
resumo_fit_3 = summary(fit_3)
coeff_fit_3 = resumo_fit_3$coefficients
coeff_fit_3 = data.frame(round(as.double(coeff_fit_3[,1]),4),round(as.double(coeff_fit_3[,2]),4),round(as.double(coeff_fit_3[,3]),4),ifelse(as.double(coeff_fit_3[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_3[,4]),4)))

names(coeff_fit_3)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_modelo_3 = data.frame(rbind(AIC(fit_3),BIC(fit_3),logLik(fit_3)))
colnames(medidas_modelo_3)=c("Modelo 3")
rownames(medidas_modelo_3)=c("AIC","BIC","Log-Verossimilhança")

#matriz de planejamento
#View(data.frame(model.matrix(fit_1)))

#step
#step(fit_1,direction="both")
#library(xtable)
#print(xtable(coeff_fit_3))
```

\vspace{1cm}
Modelo 4

Considere o seguinte modelo quadrático, ainda com o fator Sexo:

$$Y_{ij} = \beta_{1i} (x_{ij})+\beta_{2i} (x_{ij})^{2}+\varepsilon_{ij}\left\{\begin{matrix}
i=1,2\\ 
j=1,\dots, 199\\ 
\end{matrix}\right.$$

Com: $\varepsilon_{ij}\sim \mathit{N}(0,\sigma ^{2})$

\vspace{0.3cm}
\begin{itemize}
\item $Y_{ij}$: Peso do j-ésimo indíviduo do i-ésimo sexo.
\item $x_{ij}$: Altura do j-ésimo indivíduo do i-ésimo sexo.
\item $\beta_{1i}$: Incremento(positivo ou negativo) no peso quando se aumenta em uma unidade o valor da altura.
\item $\frac{-\beta_{1i}}{2\beta_{2i}}$: Valor da altura para o qual o peso esperado é máximo ou mínimo.

\end{itemize}


```{r,cache = TRUE,echo=FALSE}
#analises para o modelo 4
alt2 = dados_1$Altura^2
fit_4 = lm(Peso~-1+(Altura:Sexo)+(alt2:Sexo),data=dados_1)
resumo_fit_4 = summary(fit_4)
coeff_fit_4 = resumo_fit_4$coefficients
coeff_fit_4 = data.frame(round(as.double(coeff_fit_4[,1]),4),round(as.double(coeff_fit_4[,2]),4),round(as.double(coeff_fit_4[,3]),4),ifelse(as.double(coeff_fit_4[,4]) < 0.0001, "<0.0001", round(as.double(coeff_fit_4[,4]),4)))

names(coeff_fit_4)=c("Estimativa","EP","Valor T","Valor p")

# Estatísticas para comparação de modelos
medidas_modelo_4 = data.frame(rbind(AIC(fit_4),BIC(fit_4),logLik(fit_4)))
colnames(medidas_modelo_4)=c("Modelo 4")
rownames(medidas_modelo_4)=c("AIC","BIC","Log-Verossimilhança")

#matriz de planejamento
#View(data.frame(model.matrix(fit_1)))
#library(xtable)
#print(xtable(coeff_fit_4))
```

\vspace{1cm}
Os quatro modelos foram ajustados usando a metodologia de mínimos quadrados
ordinários, mais detalhes na referência 1(Azevedo (2016)) e análises residuais foram realizadas,conforme pode ser visto na referência 4(Paula (2013)), veja as Figuras de 4 a 11.
Podemos ver que o modelo 4 sugerido, apresentou um melhor ajuste, em comparação com os outros três, embora tanto este quanto os outros ajustes não sejam satisfatórios. 

Para o modelo 1, na figura 4, podemos notar pelo gráfico A que uma observação se destaca das demais. Já pelo gráfico B(resíduos x valores ajustados), nota-se indícios de heterocedasticidade uma vez que, a variabilidade dos resíduos parece aumentar com o aumento do valores ajustados. 
Tanto pelo gráfico C, quanto pelo gráfico D, nota-se uma leve assimetria positiva nos dados. Além disso, no gráfico D, temos a presença de outliers, o que possívelmente pode indicar a não normalidade dos dados.Além disso, o gráfico de envelopes, na figura 5, acusa um mal ajuste, devido ao comportamente levemente sistemático. Dadas as observações feitas,concluimos que o modelo não teve um ajuste adequado.

Para o modelo 2, os aspectos mencionados acima para o modelo 1 continuam presentes, com exceção do boxplot que acusou um numero maior de outliers. Como podemos ver na figura 6.

Para o modelo 3, observamos na figura 8 que há uma tendência de aumento na variabilidade dos dados com o aumento dos valores ajustados no gráfico B, além disso, podemos observar dois grupos distintos, mas isto é devido a natureza dos dados, uma vez que eles estão separados por sexo. Tal tendência, indica um possível heterocedasticidade. Nota-se pelos gráficos C e D, uma leve assimetria positiva, com presença de outliers no gráfico D.
O gráfico de envelopes, na figura 9, apresenta uma tendência e novamente,vários pontos fora dos envelopes, sugerindo assim, uma falta de normalidade.

Para o modelo 4, pela figura 10 podemos ver um ponto discrepante tanto no gráfico A como no gráfico B. No gráfico A, não se observa nenhuma tendência que indique dependência dos dados. No gráfico B, notamos um pequeno agrupamento dos dados e logo depois uma pequena dispersão dos mesmos, tal tendência, sugere uma possível heterocedasticidade dos dados.Ambos os gráficos C e D, mostram uma leva assimetria positiva, onde no gráfico C e no gráfico D, temos a presença de outliers, tanto abaixo como acima da média.
O gráfico de envelopes para o modelo 4, na figura 11, apresenta uma tendência e vários pontos fora dos envelopes, sugerindo assim, uma falta de normalidade.

Concluímos, então, que nenhum dos quatro modelos se ajustou bem. Contudo, devido ao fato de não podermos escolher modelos para além da classe dos modelos lineares normais homocedásticos, iremos continuar comparando os modelos propostos acima.

As estatísticas de comparação dos quatro modelos podem serem vistas na tabela 2. Seguindo o critério de escolha usando as estatísticas AIC e BIC, temos novamente que o modelo 4 é o modelo mais bem ajustado. Na tabela 2 também podemos ver os valores para $R^2$ e $R^2$ ajustado para cada modelo, para todos os modelos os valores são relativamente altos, indicando que os respectivos modelos explicam quase que 100% da variabilidade do dados.Sabemos porém que, a simples visualização dessas quantidades, por si só, não é
suficiente para se medir a adequabilidade do modelo.

Na Tabela 3 apresentamos os principais resultados relativos à estimação pontual e intervalar dos quatros modelos. Podemos ver que para os modelos 1 e 3, todos os parâmetros sao significativos para qualquer nível de significância usual(0,01 à 0,10).Já para o modelo 2, os parâmetros $\beta_{01}$, $\beta_{02}$ e $\beta_{12}$ são significativos para os mesmos níveis de significancia citados acima, enquanto que o parâmetro $\beta_{11}$ é significativo apenas à níveis até 0,05 e os parâmetros $\beta_{21}$ e $\beta_{22}$ não são relevantes.
E para o modelo 4, apenas o parâmetro $\beta_{22}$ é significante à qualquer nível de significancia usual, enquanto que $\beta_{21}$ é significante para níveis até 0,05, já os demais parâmetros não são significativos.

```{r,echo =FALSE,fig.width=8,fig.height=6,fig.align='center',eval=FALSE}
#Análise de resíduos para o modelo 1
library(ggplot2)
diag2norm(fit_1)
```
\begin{center}
`r legenda_graf4`
\end{center}

```{r,echo =FALSE,fig.width=6.5,fig.height=4,fig.align='center',eval=FALSE}
#gráfico de envelopes do modelo 1
envelnorm(fit_1)
```

\begin{center}
`r legenda_graf5`
\end{center}


```{r,echo =FALSE,fig.width=8,fig.height=6,fig.align='center',eval=FALSE}
##Análise de resíduos para o modelo 2
diag2norm(fit_2)
```

\begin{center}
`r legenda_graf6`
\end{center}

```{r,echo = FALSE,fig.width=7,fig.height=4,fig.align='center',eval=FALSE}
#gráfico de envelopes do modelo 2
envelnorm(fit_2)
```

\begin{center}
`r legenda_graf7`
\end{center}

```{r,echo =FALSE,fig.width=8,fig.height=6,fig.align='center',eval=FALSE}
#Análise de resíduos para o modelo 3
diag2norm(fit_3)
```

\begin{center}
`r legenda_graf8`
\end{center}

```{r,echo = TRUE,fig.width=7,fig.height=4,fig.align='center',eval=FALSE}
#gráfico de envelopes do modelo 3
envelnorm(fit_3)
```

\begin{center}
`r legenda_graf9`
\end{center}

```{r,echo =FALSE,fig.width=8,fig.height=6,fig.align='center',eval=FALSE}
##Análise de resíduos para o modelo 4
diag2norm(fit_4)
```

\begin{center}
`r legenda_graf10`
\end{center}

```{r,echo = TRUE,fig.width=7,fig.height=4, fig.align='center',eval=FALSE}
#gráfico de envelopes do modelo 4
envelnorm(fit_4)
```

\begin{center}
`r legenda_graf11`
\end{center}

```{r, echo=FALSE,results="hide"}
tabela_medidas_modelos=cbind(medidas_modelo_1,medidas_modelo_2,medidas_modelo_3,medidas_modelo_4)

rmodel1=round(summary(fit_1)$r.squared,4)
rmodel2=round(summary(fit_2)$r.squared,4)
rmodel3=round(summary(fit_3)$r.squared,4)
rmodel4=round(summary(fit_4)$r.squared,4)

rqmodel1=round(summary(fit_1)$adj.r.squared,4)
rqmodel2=round(summary(fit_2)$adj.r.squared,4)
rqmodel3=round(summary(fit_3)$adj.r.squared,4)
rqmodel4=round(summary(fit_4)$adj.r.squared,4)

#library(xtable)
#print(xtable(tabela_medidas_modelos))
```

\vspace{1cm}
\begin{center}
`r legenda_table2`
\end{center}

```{r, echo=FALSE}
options(OutDec= ",")
AIC1=round(AIC(fit_1),4)
AIC2=round(AIC(fit_2),4)
AIC3=round(AIC(fit_3),4)
AIC4=round(AIC(fit_4),4)
BIC1=round(BIC(fit_1),4)
BIC2=round(BIC(fit_2),4)
BIC3=round(BIC(fit_3),4)
BIC4=round(BIC(fit_4),4)
logLik1=round(logLik(fit_1),4)
logLik2=round(logLik(fit_2),4)
logLik3=round(logLik(fit_3),4)
logLik4=round(logLik(fit_4),4)

```

 \begin{table}[ht]
\centering
\begin{tabular}{ccccc}
\hline
& Modelo 1 & Modelo 2 & Modelo 3 & Modelo 4 \\
\hline
AIC & `r AIC1` & `r AIC2`2 & `r AIC3` & `r AIC4` \\
BIC & `r BIC1`, & `r BIC2` & `r BIC3` & `r BIC4` \\
Log-Verossimilhança & `r logLik1` & `r logLik2` & `r logLik3` & `r logLik4` \\
$R^2$ & `r rmodel1` & `r rmodel2` & `r rmodel3` & `r rmodel4`\\
$R^2$ Ajustado & `r rqmodel1` & `r rqmodel2` & `r rqmodel3` & `r rqmodel4` \\
\hline
\end{tabular}
\end{table}

```{r, echo=F}
#tabela das estimativas
tabelaestimativas=rbind(coeff_fit_1,coeff_fit_2,coeff_fit_3,coeff_fit_4)
#fazer intervalo de confiança
#library(xtable)
#print(xtable(tabelaestimativas))
```


\vspace{1cm}
\begin{center}
`r legenda_table3`
\end{center}

\begin{table}[!h]
\centering
\begin{tabular}{cccccc}
\hline
Modelo & Parâmetro & Estimativa & EP & Valor T & Valor p \\
\hline
\multirow{4}{*}{Modelo 1}
& $\beta_{01}$ & 56,8919 & 0,7620 & 74,6654 & $<$0,0001 \\
& $\beta_{02}$ & 75,8977 & 0,8558 & 88,6906 & $<$0,0001 \\
& $\beta_{11}$ & 0,6229 & 0,1347 & 4,6256 & $<$0,0001 \\
& $\beta_{12}$ & 0,9956 & 0,1336 & 7,4505 & $<$0,0001 \\
\hline
\multirow{6}{*}{Modelo 2}
& $\beta_{01}$ & 57,1353 & 0,9269 & 61,6432 & $<$0,0001 \\
& $\beta_{02}$ & 76,3053 & 1,0556 & 72,2870 & $<$0,0001 \\
& $\beta_{11}$ & 0,6132 & 0,1368 & 4,4831 & $<$0,0001 \\
& $\beta_{12}$ & 1,0051 & 0,1349 & 7,4532 & $<$0,0001 \\
& $\beta_{21}$ & -0,0076 & 0,0164 & -0,4646 & 0,6427 \\
& $\beta_{22}$ & -0,0099 & 0,0150 & -0,6639 & 0,5075 \\
\hline
\multirow{2}{*}{Modelo 3}
& $\beta_{11}$ & 0,3457 & 0,0049 & 71,1911 & $<$0,0001 \\
& $\beta_{12}$ & 0,4271 & 0,0050 & 84,6343 & $<$0,0001 \\
\hline
\multirow{4}{*}{Modelo 4}
& $\beta_{11}$ & 0,0690 & 0,1364 & 0,5059 & 0,6135 \\
& $\beta_{12}$ & -0,1354 & 0,1336 & -1,0136 & 0,3120 \\
& $\beta_{21}$ & 0,0017 & 0,0008 & 2,0310 & 0,0436 \\
& $\beta_{22}$& 0,0032 & 0,0007 & 4,2136 & $<$0,0001 \\
\hline
\end{tabular}
\end{table}

```{r ajust_model1, echo=F,eval=FALSE}
library(ggplot2)
gf1=ggplot(data=subset(dadosalt,Sexo=="F"),aes(x=Alturamf,y=Peso))+geom_point()+geom_abline(intercept=coeff_fit_1[1,1],coeff_fit_1[3,1],linetype=1)+theme_light()


gm1=ggplot(data=subset(dadosalt,Sexo=="M"),aes(x=Alturamf,y=Peso))+geom_point()+geom_abline(intercept=coeff_fit_1[2,1],coeff_fit_1[4,1],linetype=1)+theme_light()


gf2= ggplot(data=Altf,aes(x=Altura,y=Peso))+geom_point()+geom_abline(intercept = 0,slope=coeff_fit_3[1,1],linetype=1)+theme_light()

gm2= ggplot(data=Altm,aes(x=Altura,y=Peso))+geom_point()+geom_abline(intercept = 0,slope=coeff_fit_3[2,1],linetype=1)+theme_light()
grid.arrange(gf,gm,ncol=2,nrow=1)

gf3= ggplot(data=Altf,aes(x=Altura,y=Peso))+geom_point()+geom_abline(intercept = 0,slope=coeff_fit_3[1,1],linetype=1)+theme_light()

gm3= ggplot(data=Altm,aes(x=Altura,y=Peso))+geom_point()+geom_abline(intercept = 0,slope=coeff_fit_3[2,1],linetype=1)+theme_light()


gf4= ggplot(data=Altf,aes(x=Altura,y=Peso))+geom_point()+geom_abline(intercept = 0,slope=coeff_fit_3[1,1],linetype=1)+theme_light()

gm4= ggplot(data=Altm,aes(x=Altura,y=Peso))+geom_point()+geom_abline(intercept = 0,slope=coeff_fit_3[2,1],linetype=1)+theme_light()
grid.arrange(gf,gm,ncol=2,nrow=1)


grid.arrange(gf1,gm1,gf2,gm2,gf3,gm3,gf4,gm4,ncol=2,nrow=4)

```

\newpage
\vspace{0.5cm}
\begin{enumerate}
\setcounter{enumi}{3}
\item Conclusões
\end{enumerate}
\vspace{0.3cm}

Nenhum  dos quatro modelos propostos teve bom ajuste aos conjunto de dados portanto optou-se por aquele cujo ajustamento fora o menos pior dentre eles. Os modelos apontaram uma tendência crescentes nos dados, vistas na análise descritiva para ambos os sexos. Conclui-se então que o melhor modelo, segundo os critérios de seleção e comparação de modelos AIC, BIC e Log-Verossimilhança, é o modelo 4 pois teve o menor valor entre os valores entre os AIC's e BIC's e o segundo maior das Log-Verossimilhanças comparadas, mesmo que houvesse pouca diferença em relação ao modelo quatro mas como o  escolhido possui menos parâmetros e portanto, é o mais reduzido.
Vê-se que o aumento em uma unidade de altura acarreta em um aumento no peso do indivíduo.

\vspace{0.5cm}

\newpage
\begin{enumerate}
\setcounter{enumi}{4}
\item Referências Bibliográficas
\end{enumerate}

\vspace{0.3cm}

\begin{itemize}
  \item Azevedo, C. L. N (2016). Notas de aula sobre planejamento e análise de experimentos,\url{http://www.ime.unicamp.br/~cnaber/Material_ME613_2S_20
16.htm}
  \vspace{0.5cm}
  \item Faraway, J. J. (2014). Linear Models with R, Second Edition,Chapman e Hall/CRC Texts in Statistical Science
  \vspace{0.5cm}
  \item Draper, N. R. and Smith, H. (1998). Applied regression analysis, third edition. New York, NY: John Wiley e Sons.
  \vspace{0.5cm}
  \item Paula, G. A. (2013). Modelos de regressão com apoio computacional, versão pré-eliminar \url{ https://www.ime.usp.br/~giapaula/texto_2013.pdf}
  
\end{itemize}




